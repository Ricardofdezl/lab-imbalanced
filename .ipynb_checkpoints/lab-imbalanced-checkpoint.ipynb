{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB | Imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**\n",
    "\n",
    "In this challenge, we will be working with Credit Card Fraud dataset.\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/card_transdata.csv\n",
    "\n",
    "Metadata\n",
    "\n",
    "- **distance_from_home:** the distance from home where the transaction happened.\n",
    "- **distance_from_last_transaction:** the distance from last transaction happened.\n",
    "- **ratio_to_median_purchase_price:** Ratio of purchased price transaction to median purchase price.\n",
    "- **repeat_retailer:** Is the transaction happened from same retailer.\n",
    "- **used_chip:** Is the transaction through chip (credit card).\n",
    "- **used_pin_number:** Is the transaction happened by using PIN number.\n",
    "- **online_order:** Is the transaction an online order.\n",
    "- **fraud:** Is the transaction fraudulent. **0=legit** -  **1=fraud**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.877857</td>\n",
       "      <td>0.311140</td>\n",
       "      <td>1.945940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.829943</td>\n",
       "      <td>0.175592</td>\n",
       "      <td>1.294219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.091079</td>\n",
       "      <td>0.805153</td>\n",
       "      <td>0.427715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.247564</td>\n",
       "      <td>5.600044</td>\n",
       "      <td>0.362663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.190936</td>\n",
       "      <td>0.566486</td>\n",
       "      <td>2.222767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance_from_home  distance_from_last_transaction  \\\n",
       "0           57.877857                        0.311140   \n",
       "1           10.829943                        0.175592   \n",
       "2            5.091079                        0.805153   \n",
       "3            2.247564                        5.600044   \n",
       "4           44.190936                        0.566486   \n",
       "\n",
       "   ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "0                        1.945940              1.0        1.0   \n",
       "1                        1.294219              1.0        0.0   \n",
       "2                        0.427715              1.0        0.0   \n",
       "3                        0.362663              1.0        1.0   \n",
       "4                        2.222767              1.0        1.0   \n",
       "\n",
       "   used_pin_number  online_order  fraud  \n",
       "0              0.0           0.0    0.0  \n",
       "1              0.0           0.0    0.0  \n",
       "2              0.0           1.0    0.0  \n",
       "3              0.0           1.0    0.0  \n",
       "4              0.0           1.0    0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/card_transdata.csv\")\n",
    "fraud.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **1.** What is the distribution of our target variable? Can we say we're dealing with an imbalanced dataset?\n",
    "- **2.** Train a LogisticRegression.\n",
    "- **3.** Evaluate your model. Take in consideration class importance, and evaluate it by selection the correct metric.\n",
    "- **4.** Run **Oversample** in order to balance our target variable and repeat the steps above, now with balanced data. Does it improve the performance of our model? \n",
    "- **5.** Now, run **Undersample** in order to balance our target variable and repeat the steps above (1-3), now with balanced data. Does it improve the performance of our model?\n",
    "- **6.** Finally, run **SMOTE** in order to balance our target variable and repeat the steps above (1-3), now with balanced data. Does it improve the performance of our model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distance_from_home                0\n",
       "distance_from_last_transaction    0\n",
       "ratio_to_median_purchase_price    0\n",
       "repeat_retailer                   0\n",
       "used_chip                         0\n",
       "used_pin_number                   0\n",
       "online_order                      0\n",
       "fraud                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraud\n",
      "0.0    0.912597\n",
      "1.0    0.087403\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHNCAYAAADiyVpMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA4nElEQVR4nO3deVxU9f7H8fcIMiAKJCiCIpJbmmmKPxXMXTGX0m4318S9a3bdMLui5ZaFddNcUrRyyeqa1VVvpenFNjG1q7hlLuWKC2SKAm7Icn5/9GAeTYDCiA4eX8/H4zwezfd8zzmfc0aa93zPMhbDMAwBAACYRClnFwAAAFCcCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDfAnyxbtkwWiyXf6fnnn3d2eTYDBgxQtWrVnF2GqlWrpq5du97RbR4/flwWi0XLli2ztW3ZskVTpkzRxYsXC7VsYabjx4/f1v1wlitXrmjKlCn69ttv88zL/fdv1n3HvcHV2QUAJdXSpUv1wAMP2LUFBgY6qRr8UUBAgLZu3arq1avb2rZs2aKpU6dqwIAB8vHxuemyfzR8+HClpqbqww8/zNPXjK5cuaKpU6dKklq3bm03r0uXLtq6datp9x33BsINUIB69eqpcePGheqbmZkpi8UiV1f+pO4Eq9WqZs2aFduyXl5eun79+k3XefXqVXl4eDi03btFhQoVVKFCBWeXAdwSTksBRfTtt9/KYrHo/fff19ixY1W5cmVZrVYdPnxYv/32m4YPH666deuqbNmyqlixotq2bav4+Ph81/Hn0wL5nW6Rfj9VULt2bVmtVtWpU0fLly8vVK3du3dXcHCwcnJy8sxr2rSpGjVqZHv9ySefqGnTpvL29laZMmV0//33a9CgQYU7KDdhGIYWLFighx9+WB4eHrrvvvv017/+VUePHs3T79VXX1VwcLDc3d3VuHFjxcXFqXXr1nYjDH8+TlOmTNG4ceMkSSEhIbbTSvmddims3NNtq1atUsOGDeXu7m4b7Zg/f75atmypihUrytPTUw899JBef/11ZWZm2q2jdevWqlevnrZv364WLVrYjuuMGTPs3pOcnBxNnz5dtWvXloeHh3x8fFS/fn3NmTPH1ufw4cMaOHCgatasqTJlyqhy5cp67LHH9OOPP+ap/eLFixo7dqzuv/9+Wa1WVaxYUZ07d9bBgwd1/PhxW3iZOnWq7VgNGDBAUsGnpZYsWaIGDRrI3d1d5cuX1xNPPKEDBw7Y9RkwYIDKli2rw4cPq3PnzipbtqyCgoI0duxYZWRk2PWNjY1VgwYNVLZsWZUrV04PPPCAJkyYULQ3CSgAXzOBAmRnZysrK8uu7Y8jM9HR0QoLC9PChQtVqlQpVaxYUb/99pskafLkyapUqZIuXbqk1atXq3Xr1vrqq6/ynAIojGXLlmngwIHq1q2bZs6cqdTUVE2ZMkUZGRkqVerG308GDRqkbt266euvv1b79u1t7QcPHtT//vc/zZ07V5K0detW9ezZUz179tSUKVPk7u6uEydO6Ouvvy5yvfn529/+pmXLlmnkyJF67bXXlJKSomnTpik8PFx79uyRv7+/JGnixImKiYnRM888o7/85S86efKkhgwZoszMTNWqVavA9Q8ZMkQpKSmaN2+eVq1aZTulUrdu3Vuqe+fOnTpw4IBefPFFhYSEyNPTU5J05MgR9enTRyEhIXJzc9OePXv0yiuv6ODBg1qyZIndOpKTk9W3b1+NHTtWkydP1urVqxUdHa3AwEBFRkZKkl5//XVNmTJFL774olq2bKnMzEwdPHjQ7vqhM2fOyNfXVzNmzFCFChWUkpKi9957T02bNtWuXbtUu3ZtSVJ6eroeeeQRHT9+XP/4xz/UtGlTXbp0SZs2bVJSUpLCw8O1fv16Pfrooxo8eLCGDBkiSTccrYmJidGECRPUu3dvxcTE6Pz585oyZYrCwsK0fft21axZ09Y3MzNTjz/+uAYPHqyxY8dq06ZNevnll+Xt7a1JkyZJkj766CMNHz5cI0aM0BtvvKFSpUrp8OHD2r9//y29X4CNAcDO0qVLDUn5TpmZmcY333xjSDJatmx503VlZWUZmZmZRrt27YwnnnjC1p67jm+++cau/7FjxwxJxtKlSw3DMIzs7GwjMDDQaNSokZGTk2Prd/z4caN06dJGcHDwDbefmZlp+Pv7G3369LFrf+GFFww3Nzfj3LlzhmEYxhtvvGFIMi5evHjTffqz4OBgo0uXLgXO37p1qyHJmDlzpl37yZMnDQ8PD+OFF14wDMMwUlJSDKvVavTs2TPf5Vu1amVr+/NxMgzD+Oc//2lIMo4dO1bkfWjVqpXx4IMP5tkvFxcX49ChQzdcNjs728jMzDSWL19uuLi4GCkpKXbrlWT88MMPdsvUrVvX6Nixo+11165djYcffrhINWdlZRnXr183atasaYwZM8bWPm3aNEOSERcXV+Cyv/32myHJmDx5cp55uf/+c4/jhQsXDA8PD6Nz5852/RITEw2r1Wr3b6t///6GJOPjjz+269u5c2ejdu3attd///vfDR8fn6LsLlAknJYCCrB8+XJt377dbvrjyM2TTz6Z73ILFy5Uo0aN5O7uLldXV5UuXVpfffVVniH8wjh06JDOnDmjPn36yGKx2NqDg4MVHh5+0+VdXV319NNPa9WqVUpNTZX0+4jU+++/r27dusnX11eS9H//93+SpB49eujjjz/W6dOni1xrQb744gtZLBY9/fTTysrKsk2VKlVSgwYNbKeOtm3bpoyMDPXo0cNu+WbNmjntrrD69evnO2K0a9cuPf744/L19ZWLi4tKly6tyMhIZWdn6+eff7brW6lSJTVp0iTPek+cOGF73aRJE+3Zs0fDhw/Xhg0blJaWlmebWVlZevXVV1W3bl25ubnJ1dVVbm5u+uWXX+z+bX355ZeqVauW3Ujdrdi6dauuXr1qO22VKygoSG3bttVXX31l126xWPTYY4/ZteW3vxcvXlTv3r31n//8R+fOnSuWWoFchBugAHXq1FHjxo3tpj/K726SWbNm6dlnn1XTpk3173//W9u2bdP27dv16KOP6urVq0Wu4fz585J+/4D8s/za8jNo0CBdu3ZNH330kSRpw4YNSkpK0sCBA219WrZsqTVr1igrK0uRkZGqUqWK6tWrpxUrVhS55j/79ddfZRiG/P39Vbp0abtp27Zttg+23H3NPUX1R/m13Qn5vceJiYlq0aKFTp8+rTlz5ig+Pl7bt2/X/PnzJSnP+5wbIP/IarXa9YuOjtYbb7yhbdu2qVOnTvL19VW7du20Y8cOW5+oqCi99NJL6t69uz7//HP98MMP2r59uxo0aGC3rt9++01VqlS55X3Plfu+5HcsAgMDbfNzlSlTRu7u7nZtVqtV165ds73u16+flixZohMnTujJJ59UxYoV1bRpU8XFxRVb3bi3cc0N4KA/jqTk+uCDD9S6dWvFxsbataenp9u9zv2f/58vsvzzN9jcD8bk5OQ828qvLT9169ZVkyZNtHTpUv3tb3/T0qVLFRgYqIiICLt+3bp1U7du3ZSRkaFt27YpJiZGffr0UbVq1RQWFlaobeXHz89PFotF8fHxslqteebntuXu66+//pqnT3JyslNGb/J7j9esWaPLly9r1apVCg4OtrXv3r3b4e24uroqKipKUVFRunjxojZu3KgJEyaoY8eOOnnypMqUKaMPPvhAkZGRevXVV+2WPXfunN2t7xUqVNCpU6ccruXPct+XpKSkPPPOnDkjPz8/h9Y7cOBADRw4UJcvX9amTZs0efJkde3aVT///LPdcQUcwcgNUIwsFkueD/C9e/fmea5K7gf13r177do/++wzu9e1a9dWQECAVqxYIcMwbO0nTpzQli1bCl3XwIED9cMPP2jz5s36/PPP1b9/f7m4uOTb12q1qlWrVnrttdck/X4K5lZ07dpVhmHo9OnTeUbCGjdurIceekjS73dvWa1WrVy50m75bdu22Z3SKEjucXdkhKwocgPPH99nwzD0zjvvFMv6fXx89Ne//lXPPfecUlJSbHct5fdva+3atXlOIXbq1Ek///zzDS8GL8qxCgsLk4eHhz744AO79lOnTunrr79Wu3btCrNbBfL09FSnTp00ceJEXb9+XT/99NMtrQ+QGLkBilXXrl318ssva/LkyWrVqpUOHTqkadOmKSQkxO7Oq0qVKql9+/aKiYnRfffdp+DgYH311VdatWqV3fpKlSqll19+WUOGDNETTzyhoUOH6uLFi5oyZUqhT0tJUu/evRUVFaXevXsrIyMjz/UTkyZN0qlTp9SuXTtVqVJFFy9e1Jw5c1S6dGm1atXqputPTk7Wp59+mqe9WrVqat68uZ555hkNHDhQO3bsUMuWLeXp6amkpCRt3rxZDz30kJ599lmVL19eUVFRtmPyxBNP6NSpU5o6daoCAgJuemdYbkiaM2eO+vfvr9KlS6t27doqV65coY9TYXTo0EFubm7q3bu3XnjhBV27dk2xsbG6cOGCw+t87LHHbM9VqlChgk6cOKHZs2crODjYdidS165dtWzZMj3wwAOqX7++EhIS9M9//jPPKajRo0dr5cqV6tatm8aPH68mTZro6tWr+u6779S1a1e1adNG5cqVU3BwsP7zn/+oXbt2Kl++vPz8/PIdHfPx8dFLL72kCRMmKDIyUr1799b58+c1depUubu7a/LkyUXe36FDh8rDw0PNmzdXQECAkpOTFRMTI29vb9v1X8Atce71zEDJk3u3yPbt2/Odn3un0yeffJJnXkZGhvH8888blStXNtzd3Y1GjRoZa9asMfr375/nzqakpCTjr3/9q1G+fHnD29vbePrpp40dO3bkuQvIMAzj3XffNWrWrGm4ubkZtWrVMpYsWZLvOm+kT58+hiSjefPmeeZ98cUXRqdOnYzKlSsbbm5uRsWKFY3OnTsb8fHxN11vcHBwgXeX9e/f39ZvyZIlRtOmTQ1PT0/Dw8PDqF69uhEZGWns2LHD1icnJ8eYPn26UaVKFcPNzc2oX7++8cUXXxgNGjSwu9ssv7ulDMMwoqOjjcDAQKNUqVL53o1WkILuliroLrDPP//caNCggeHu7m5UrlzZGDdunPHll1/m2WZ+6zUMI897N3PmTCM8PNzw8/Mz3NzcjKpVqxqDBw82jh8/butz4cIFY/DgwUbFihWNMmXKGI888ogRHx9vtGrVyu5Osty+o0aNMqpWrWqULl3aqFixotGlSxfj4MGDtj4bN240GjZsaFitVrv36s93S+V69913jfr16xtubm6Gt7e30a1bN+Onn37Ks1+enp559nfy5MnGHz9u3nvvPaNNmzaGv7+/4ebmZgQGBho9evQw9u7dm+/xBorKYhh/GOsGgBLm2LFjeuCBBzR58mQe8gagUAg3AEqMPXv2aMWKFQoPD5eXl5cOHTqk119/XWlpadq3b5/T7poCcHfhmhsAJYanp6d27NihxYsX6+LFi/L29lbr1q31yiuvEGwAFBojNwAAwFS4FRwAAJgK4QYAAJgK4QYAAJjKPXdBcU5Ojs6cOaNy5crl+2h1AABQ8hiGofT0dAUGBt70oZ73XLg5c+aMgoKCnF0GAABwwMmTJ2/647D3XLjJfRT7yZMn5eXl5eRqAABAYaSlpSkoKKhQP6lyz4Wb3FNRXl5ehBsAAO4yhbmkhAuKAQCAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqbg6uwDcOdXGr3V2CbiDjs/o4uwSAMApGLkBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACm4vRws2DBAoWEhMjd3V2hoaGKj4+/Yf8PP/xQDRo0UJkyZRQQEKCBAwfq/Pnzd6haAABQ0jk13KxcuVKjR4/WxIkTtWvXLrVo0UKdOnVSYmJivv03b96syMhIDR48WD/99JM++eQTbd++XUOGDLnDlQMAgJLKqeFm1qxZGjx4sIYMGaI6depo9uzZCgoKUmxsbL79t23bpmrVqmnkyJEKCQnRI488or/97W/asWPHHa4cAACUVE4LN9evX1dCQoIiIiLs2iMiIrRly5Z8lwkPD9epU6e0bt06GYahX3/9VZ9++qm6dOlS4HYyMjKUlpZmNwEAAPNyWrg5d+6csrOz5e/vb9fu7++v5OTkfJcJDw/Xhx9+qJ49e8rNzU2VKlWSj4+P5s2bV+B2YmJi5O3tbZuCgoKKdT8AAEDJ4vQLii0Wi91rwzDytOXav3+/Ro4cqUmTJikhIUHr16/XsWPHNGzYsALXHx0drdTUVNt08uTJYq0fAACULK7O2rCfn59cXFzyjNKcPXs2z2hOrpiYGDVv3lzjxo2TJNWvX1+enp5q0aKFpk+froCAgDzLWK1WWa3W4t8BAABQIjlt5MbNzU2hoaGKi4uza4+Li1N4eHi+y1y5ckWlStmX7OLiIun3ER8AAACnnpaKiorSu+++qyVLlujAgQMaM2aMEhMTbaeZoqOjFRkZaev/2GOPadWqVYqNjdXRo0f1/fffa+TIkWrSpIkCAwOdtRsAAKAEcdppKUnq2bOnzp8/r2nTpikpKUn16tXTunXrFBwcLElKSkqye+bNgAEDlJ6errfeektjx46Vj4+P2rZtq9dee81ZuwAAAEoYi3GPnc9JS0uTt7e3UlNT5eXl5exy7qhq49c6uwTcQcdnFPyIBAC42xTl89vpd0sBAAAUJ8INAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFaeHmwULFigkJETu7u4KDQ1VfHz8DftnZGRo4sSJCg4OltVqVfXq1bVkyZI7VC0AACjpXJ258ZUrV2r06NFasGCBmjdvrkWLFqlTp07av3+/qlatmu8yPXr00K+//qrFixerRo0aOnv2rLKysu5w5QAAoKSyGIZhOGvjTZs2VaNGjRQbG2trq1Onjrp3766YmJg8/devX69evXrp6NGjKl++vEPbTEtLk7e3t1JTU+Xl5eVw7XejauPXOrsE3EHHZ3RxdgkAUGyK8vnttNNS169fV0JCgiIiIuzaIyIitGXLlnyX+eyzz9S4cWO9/vrrqly5smrVqqXnn39eV69eLXA7GRkZSktLs5sAAIB5Oe201Llz55SdnS1/f3+7dn9/fyUnJ+e7zNGjR7V582a5u7tr9erVOnfunIYPH66UlJQCr7uJiYnR1KlTi71+AABQMjn9gmKLxWL32jCMPG25cnJyZLFY9OGHH6pJkybq3LmzZs2apWXLlhU4ehMdHa3U1FTbdPLkyWLfBwAAUHI4beTGz89PLi4ueUZpzp49m2c0J1dAQIAqV64sb29vW1udOnVkGIZOnTqlmjVr5lnGarXKarUWb/EAAKDEctrIjZubm0JDQxUXF2fXHhcXp/Dw8HyXad68uc6cOaNLly7Z2n7++WeVKlVKVapUua31AgCAu4NTT0tFRUXp3Xff1ZIlS3TgwAGNGTNGiYmJGjZsmKTfTylFRkba+vfp00e+vr4aOHCg9u/fr02bNmncuHEaNGiQPDw8nLUbAACgBHHqc2569uyp8+fPa9q0aUpKSlK9evW0bt06BQcHS5KSkpKUmJho61+2bFnFxcVpxIgRaty4sXx9fdWjRw9Nnz7dWbsAAABKGKc+58YZeM4N7hU85waAmdwVz7kBAAC4HQg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVBx6QvHly5c1Y8YMffXVVzp79qxycnLs5h89erRYigMAACgqh8LNkCFD9N1336lfv34KCAiQxWIp7roAAAAc4lC4+fLLL7V27Vo1b968uOsBAAC4JQ5dc3PfffepfPnyxV0LAADALXMo3Lz88suaNGmSrly5Utz1AAAA3BKHTkvNnDlTR44ckb+/v6pVq6bSpUvbzd+5c2exFAcAAFBUDoWb7t27F3MZAAAAxcOhcDN58uTirgMAAKBYOBRuciUkJOjAgQOyWCyqW7euGjZsWFx1AQAAOMShcHP27Fn16tVL3377rXx8fGQYhlJTU9WmTRt99NFHqlChQnHXCQAAUCgO3S01YsQIpaWl6aefflJKSoouXLigffv2KS0tTSNHjizuGgEAAArNoZGb9evXa+PGjapTp46trW7dupo/f74iIiKKrTgAAICicmjkJicnJ8/t35JUunTpPL8zBQAAcCc5FG7atm2rUaNG6cyZM7a206dPa8yYMWrXrl2xFQcAAFBUDoWbt956S+np6apWrZqqV6+uGjVqKCQkROnp6Zo3b15x1wgAAFBoDl1zExQUpJ07dyouLk4HDx6UYRiqW7eu2rdvX9z1AQAAFMktPeemQ4cO6tChQ3HVAgAAcMsKHW7mzp2rZ555Ru7u7po7d+4N+3I7OAAAcJZCh5s333xTffv2lbu7u958880C+1ksFsINAABwmkKHm2PHjuX73wAAACWJQ3dLTZs2TVeuXMnTfvXqVU2bNu2WiwIAAHCUQ+Fm6tSpunTpUp72K1euaOrUqbdcFAAAgKMcCjeGYchiseRp37Nnj8qXL3/LRQEAADiqSLeC33fffbJYLLJYLKpVq5ZdwMnOztalS5c0bNiwYi8SAACgsIoUbmbPni3DMDRo0CBNnTpV3t7etnlubm6qVq2awsLCir1IAACAwipSuOnfv7+ysrIkSe3bt1eVKlVuS1EAAACOKvI1N66urho+fLiys7NvRz0AAAC3xKELips2bapdu3YVdy0AAAC3zKHflho+fLjGjh2rU6dOKTQ0VJ6ennbz69evXyzFAQAAFJVD4aZnz56S7H9DymKx2G4R55QVAABwFofCDT+/AAAASiqHwk1wcHBx1wEAAFAsHAo3knTkyBHNnj1bBw4ckMViUZ06dTRq1ChVr169OOsDAAAoEofultqwYYPq1q2r//3vf6pfv77q1aunH374QQ8++KDi4uKKu0YAAIBCc2jkZvz48RozZoxmzJiRp/0f//iHOnToUCzFAQAAFJVDIzcHDhzQ4MGD87QPGjRI+/fvv+WiAAAAHOVQuKlQoYJ2796dp3337t2qWLHirdYEAADgMIdOSw0dOlTPPPOMjh49qvDwcFksFm3evFmvvfaaxo4dW9w1AgAAFJpD4eall15SuXLlNHPmTEVHR0uSAgMDNWXKFLsH+wEAANxpDoUbi8WiMWPGaMyYMUpPT5cklStXrlgLAwAAcITDz7mRpLNnz+rQoUOyWCyqXbu2KlSoUFx1AQAAOMShC4rT0tLUr18/BQYGqlWrVmrZsqUCAwP19NNPKzU1tbhrBAAAKDSHws2QIUP0ww8/aO3atbp48aJSU1P1xRdfaMeOHRo6dGhx1wgAAFBoDp2WWrt2rTZs2KBHHnnE1taxY0e98847evTRR4utOAAAgKJyaOTG19dX3t7eedq9vb1133333XJRAAAAjnIo3Lz44ouKiopSUlKSrS05OVnjxo3TSy+9VGzFAQAAFJVDp6ViY2N1+PBhBQcHq2rVqpKkxMREWa1W/fbbb1q0aJGt786dO4unUgAAgEJwKNx07969mMsAAAAoHg6Fm8mTJxd3HQAAAMXilh7il5CQoAMHDshisahu3bpq2LBhcdUFAADgEIfCzdmzZ9WrVy99++238vHxkWEYSk1NVZs2bfTRRx/xpGIAAOA0Dt0tNWLECKWlpemnn35SSkqKLly4oH379iktLY0fzgQAAE7l0MjN+vXrtXHjRtWpU8fWVrduXc2fP18RERHFVhwAAEBROTRyk5OTo9KlS+dpL126tHJycm65KAAAAEc5FG7atm2rUaNG6cyZM7a206dPa8yYMWrXrl2xFQcAAFBUDoWbt956S+np6apWrZqqV6+uGjVqKCQkROnp6Zo3b15x1wgAAFBoDl1zExQUpJ07dyouLk4HDx6UYRiqW7eu2rdvX9z1AQAAFEmRw01WVpbc3d21e/dudejQQR06dLgddQEAADikyKelXF1dFRwcrOzs7GIpYMGCBQoJCZG7u7tCQ0MVHx9fqOW+//57ubq66uGHHy6WOgAAgDk4/Kvg0dHRSklJuaWNr1y5UqNHj9bEiRO1a9cutWjRQp06dVJiYuINl0tNTVVkZCQXLwMAgDwshmEYRV2oYcOGOnz4sDIzMxUcHCxPT0+7+YX9JfCmTZuqUaNGio2NtbXVqVNH3bt3V0xMTIHL9erVSzVr1pSLi4vWrFmj3bt3F7r2tLQ0eXt7KzU1VV5eXoVezgyqjV/r7BJwBx2f0cXZJQBAsSnK57fDvwpusVjkQC6yuX79uhISEjR+/Hi79oiICG3ZsqXA5ZYuXaojR47ogw8+0PTp02+6nYyMDGVkZNhep6WlOVwzAAAo+YoUbq5cuaJx48ZpzZo1yszMVLt27TRv3jz5+fkVecPnzp1Tdna2/P397dr9/f2VnJyc7zK//PKLxo8fr/j4eLm6Fq70mJgYTZ06tcj1AQCAu1ORrrmZPHmyli1bpi5duqh3797auHGjnn322VsqwGKx2L02DCNPmyRlZ2erT58+mjp1qmrVqlXo9UdHRys1NdU2nTx58pbqBQAAJVuRRm5WrVqlxYsXq1evXpKkvn37qnnz5srOzpaLi0uRNuzn5ycXF5c8ozRnz57NM5ojSenp6dqxY4d27dqlv//975J+/xkIwzDk6uqq//73v2rbtm2e5axWq6xWa5FqAwAAd68ijdycPHlSLVq0sL1u0qSJXF1d7X6GobDc3NwUGhqquLg4u/a4uDiFh4fn6e/l5aUff/xRu3fvtk3Dhg1T7dq1tXv3bjVt2rTINQAAAPMp0shNdna23Nzc7Ffg6qqsrCyHNh4VFaV+/fqpcePGCgsL09tvv63ExEQNGzZM0u+nlE6fPq3ly5erVKlSqlevnt3yFStWlLu7e552AABw7ypSuDEMQwMGDLA7zXPt2jUNGzbM7nbwVatWFWp9PXv21Pnz5zVt2jQlJSWpXr16WrdunYKDgyVJSUlJN33mDQAAwB8V6Tk3AwcOLFS/pUuXOlzQ7cZzbnCv4Dk3AMzktj3npiSHFgAAAMnBn18AAAAoqQg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVJwebhYsWKCQkBC5u7srNDRU8fHxBfZdtWqVOnTooAoVKsjLy0thYWHasGHDHawWAACUdE4NNytXrtTo0aM1ceJE7dq1Sy1atFCnTp2UmJiYb/9NmzapQ4cOWrdunRISEtSmTRs99thj2rVr1x2uHAAAlFQWwzAMZ228adOmatSokWJjY21tderUUffu3RUTE1OodTz44IPq2bOnJk2aVKj+aWlp8vb2Vmpqqry8vByq+25VbfxaZ5eAO+j4jC7OLgEAik1RPr+dNnJz/fp1JSQkKCIiwq49IiJCW7ZsKdQ6cnJylJ6ervLlyxfYJyMjQ2lpaXYTAAAwL6eFm3Pnzik7O1v+/v527f7+/kpOTi7UOmbOnKnLly+rR48eBfaJiYmRt7e3bQoKCrqlugEAQMnm9AuKLRaL3WvDMPK05WfFihWaMmWKVq5cqYoVKxbYLzo6Wqmpqbbp5MmTt1wzAAAouVydtWE/Pz+5uLjkGaU5e/ZsntGcP1u5cqUGDx6sTz75RO3bt79hX6vVKqvVesv1AgCAu4PTRm7c3NwUGhqquLg4u/a4uDiFh4cXuNyKFSs0YMAA/etf/1KXLlwwCQAA7Dlt5EaSoqKi1K9fPzVu3FhhYWF6++23lZiYqGHDhkn6/ZTS6dOntXz5ckm/B5vIyEjNmTNHzZo1s436eHh4yNvb22n7AQAASg6nhpuePXvq/PnzmjZtmpKSklSvXj2tW7dOwcHBkqSkpCS7Z94sWrRIWVlZeu655/Tcc8/Z2vv3769ly5bd6fIBAEAJ5NTn3DgDz7nBvYLn3AAwk7viOTcAAAC3A+EGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYiquzCwAA3Lpq49c6uwTcQcdndHF2CSUaIzcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUnB5uFixYoJCQELm7uys0NFTx8fE37P/dd98pNDRU7u7uuv/++7Vw4cI7VCkAALgbODXcrFy5UqNHj9bEiRO1a9cutWjRQp06dVJiYmK+/Y8dO6bOnTurRYsW2rVrlyZMmKCRI0fq3//+9x2uHAAAlFRODTezZs3S4MGDNWTIENWpU0ezZ89WUFCQYmNj8+2/cOFCVa1aVbNnz1adOnU0ZMgQDRo0SG+88cYdrhwAAJRUTgs3169fV0JCgiIiIuzaIyIitGXLlnyX2bp1a57+HTt21I4dO5SZmXnbagUAAHcPV2dt+Ny5c8rOzpa/v79du7+/v5KTk/NdJjk5Od/+WVlZOnfunAICAvIsk5GRoYyMDNvr1NRUSVJaWtqt7sJdJyfjirNLwB10L/4bv5fx931vuRf/vnP32TCMm/Z1WrjJZbFY7F4bhpGn7Wb982vPFRMTo6lTp+ZpDwoKKmqpwF3Fe7azKwBwu9zLf9/p6eny9va+YR+nhRs/Pz+5uLjkGaU5e/ZsntGZXJUqVcq3v6urq3x9ffNdJjo6WlFRUbbXOTk5SklJka+v7w1DFMwhLS1NQUFBOnnypLy8vJxdDoBixN/3vcUwDKWnpyswMPCmfZ0Wbtzc3BQaGqq4uDg98cQTtva4uDh169Yt32XCwsL0+eef27X997//VePGjVW6dOl8l7FarbJarXZtPj4+t1Y87jpeXl78zw8wKf6+7x03G7HJ5dS7paKiovTuu+9qyZIlOnDggMaMGaPExEQNGzZM0u+jLpGRkbb+w4YN04kTJxQVFaUDBw5oyZIlWrx4sZ5//nln7QIAAChhnHrNTc+ePXX+/HlNmzZNSUlJqlevntatW6fg4GBJUlJSkt0zb0JCQrRu3TqNGTNG8+fPV2BgoObOnasnn3zSWbsAAABKGItRmMuOgbtURkaGYmJiFB0dnef0JIC7G3/fKAjhBgAAmIrTf1sKAACgOBFuAACAqRBuAACAqRBuAACAqRBuAACAqTj9t6WA2yE7O1vnzp2TxWKRr6+vXFxcnF0SAOAOYeQGprJ69Wo1b95cZcqUUWBgoAICAlSmTBk1b95ca9ascXZ5AIpJdna2fv31V509e1bZ2dnOLgclDOEGprFo0SL16tVL9evX18qVK7V582bFx8dr5cqVql+/vnr16qV33nnH2WUCuAV8gUFh8BA/mEaNGjUUHR2twYMH5zt/yZIleuWVV3TkyJE7XBmA4rBo0SKNHDlSgwYNUseOHeXv7y/DMHT27Flt2LBBS5cu1bx58zR06FBnlwonI9zANDw8PLR7927Vrl073/kHDx5Uw4YNdfXq1TtcGYDiwBcYFBanpWAaDz74oN5+++0C57/zzjt68MEH72BFAIrT6dOn9cgjjxQ4Pzw8XGfOnLmDFaGk4m4pmMbMmTPVpUsXrV+/XhEREfL395fFYlFycrLi4uJ04sQJrVu3ztllAnBQ7heYmTNn5jufLzDIxWkpmMrx48cVGxurbdu2KTk5WZJUqVIlhYWFadiwYapWrZpzCwTgsO+++05dunRRcHDwDb/AtGjRwtmlwskINwCAuwZfYFAYhBsAAGAqXFCMe0b//v3Vtm1bZ5cBALjNCDe4ZwQGBio4ONjZZQC4TfgCg1zcLYV7RkxMjLNLAHAbBQYGqlQpvrODa25gMqdOnVJsbKy2bNmi5ORkWSwW+fv7Kzw8XM8++6yqVKni7BIBALcZ4QamsXnzZnXq1ElBQUG220RzH80eFxenkydP6ssvv1Tz5s2dXSqA2+DkyZOaPHmylixZ4uxS4GSEG5jG//3f/+mRRx7Rm2++me/8MWPGaPPmzdq+ffsdrgzAnbBnzx41atSIXwkH4QbmwW9LAeb22Wef3XD+0aNHNXbsWMINuKAY5hEQEKAtW7YUGG62bt2qgICAO1wVgOLSvXt3WSwW3eg7ucViuYMVoaQi3MA0nn/+eQ0bNkwJCQnq0KFDnkezv/vuu5o9e7azywTgoICAAM2fP1/du3fPd/7u3bsVGhp6Z4tCiUS4gWkMHz5cvr6+evPNN7Vo0SLb0LSLi4tCQ0O1fPly9ejRw8lVAnBUaGiodu7cWWC4udmoDu4dXHMDU8rMzNS5c+ckSX5+fipdurSTKwJwq+Lj43X58mU9+uij+c6/fPmyduzYoVatWt3hylDSEG4AAICp8ChHAABgKoQbAABgKoQbAABgKoQbALdkwIABBd698kf9+vXTq6++Wuj1ZmRkqGrVqkpISLiF6kqmwh6z/Bw6dEiVKlVSenp6oZd566239Pjjjzu0PeBuRLgB7kIDBgyQxWLJMx0+fNjZpeVr7969Wrt2rUaMGGFrW7VqlTp27Cg/Pz9ZLBbt3r3bbhmr1arnn39e//jHP+5orcuWLZOPj89t3cacOXO0bNky2+vWrVtr9OjRhVp24sSJeu6551SuXDlb248//qhWrVrJw8NDlStX1rRp0+xuiR46dKi2b9+uzZs3F9cuACUa4Qa4Sz366KNKSkqym0JCQvL0u379uhOqs/fWW2/pqaeesvtAvnz5spo3b64ZM2YUuFzfvn0VHx+vAwcO3Iky7xhvb2+HAtSpU6f02WefaeDAgba2tLQ0dejQQYGBgdq+fbvmzZunN954Q7NmzbL1sVqt6tOnj+bNm1cc5QMlHuEGuEtZrVZVqlTJbnJxcVHr1q3197//XVFRUfLz81OHDh0kSbNmzdJDDz0kT09PBQUFafjw4bp06ZJtfVOmTNHDDz9st43Zs2erWrVqttfZ2dmKioqSj4+PfH199cILL9z0oWk5OTn65JNP8pwW6devnyZNmqT27dsXuKyvr6/Cw8O1YsWKAtddpUoVLVy40K59586dslgsOnr0qG3fqlatKqvVqsDAQI0cOfKGNd9IamqqnnnmGVWsWFFeXl5q27at9uzZY9dn+vTpqlixosqVK6chQ4Zo/Pjxdsf2j6elBgwYoO+++05z5syxjcAdP348321//PHHatCggapUqWJr+/DDD3Xt2jUtW7ZM9erV01/+8hdNmDBBs2bNsntvHn/8ca1Zs4bfVsM9gXADmNB7770nV1dXff/991q0aJEkqVSpUpo7d6727dun9957T19//bVeeOGFIq135syZWrJkiRYvXqzNmzcrJSVFq1evvuEye/fu1cWLF9W4cWOH9qVJkyaKj4/Pd16pUqXUq1cvffjhh3bt//rXvxQWFqb7779fn376qe2p1b/88ovWrFmjhx56yKFaDMNQly5dlJycrHXr1ikhIUGNGjVSu3btlJKSIun3sPHKK6/otddeU0JCgqpWrarY2NgC1zlnzhyFhYVp6NChthG4oKCgfPtu2rQpz3HcunWrWrVqJavVamvr2LGjzpw5YxeSGjdurMzMTP3vf/9zaN+BuwnhBrhLffHFFypbtqxteuqpp2zzatSooddff121a9fWAw88IEkaPXq02rRpo5CQELVt21Yvv/yyPv744yJtc/bs2YqOjtaTTz6pOnXqaOHChfL29r7hMsePH5eLi4sqVqxY9J2UVLly5QJHMqTfT119//33OnHihKTfR3M++ugjPf3005KkxMREVapUSe3bt1fVqlXVpEkTDR061KFavvnmG/3444/65JNP1LhxY9WsWVNvvPGGfHx89Omnn0qS5s2bp8GDB2vgwIGqVauWJk2adMMw5e3tLTc3N5UpU8ZuBC4/x48fV2BgoF1bcnKy/P397dpyXycnJ9vaPD095ePjc8NjCZgF4Qa4S7Vp00a7d++2TXPnzrXNy2+U5JtvvlGHDh1UuXJllStXTpGRkTp//rwuX75cqO2lpqYqKSlJYWFhtjZXV9ebjshcvXpVVqvV4V9r9vDw0JUrVwqc37BhQz3wwAO2U1ffffedzp49a/sdsaeeekpXr17V/fffr6FDh2r16tXKyspyqJaEhARdunRJvr6+dsHy2LFjOnLkiKTf72Zq0qSJ3XJ/fu2oq1evyt3dPU/7n49t7umoP7ff7FgCZkG4Ae5Snp6eqlGjhm0KCAiwm/dHJ06cUOfOnVWvXj39+9//VkJCgubPny/p99/hkn4/xfPn62dy590KPz8/XblyxeELm1NSUlShQoUb9unbt6/+9a9/Sfr9lFTuXViSFBQUpEOHDmn+/Pny8PDQ8OHD1bJlS4f2LScnRwEBAXahcvfu3Tp06JDGjRtn61dQ2LhVfn5+unDhgl1bpUqV7EZoJOns2bOSlGdEpzDHEjADwg1wD9ixY4eysrI0c+ZMNWvWTLVq1dKZM2fs+lSoUEHJycl2H8R/vD3b29tbAQEB2rZtm60tKyvrps+hyb2Qdv/+/Q7Vvm/fPjVs2PCGffr06aMff/xRCQkJ+vTTT9W3b1+7+R4eHnr88cc1d+5cffvtt9q6dat+/PHHItfSqFEjJScny9XV1S5Y1qhRwxamateunee6lh07dtxwvW5ubrZfsb+Rhg0b5jmOYWFh2rRpk114/O9//6vAwEC7i8GPHDmia9eu3fRYAmZAuAHuAdWrV1dWVpbmzZuno0eP6v33389zh1Hr1q3122+/6fXXX9eRI0c0f/58ffnll3Z9Ro0apRkzZmj16tU6ePCghg8frosXL95w2xUqVFCjRo3yPGMlJSVFu3fvtn1YHzp0SLt3784zChEfH6+IiIgbbiMkJETh4eEaPHiwsrKy1K1bN9u8ZcuWafHixdq3b59t3z08PBQcHFzg+rKzs/OMzuzfv1/t27dXWFiYunfvrg0bNuj48ePasmWLXnzxRVuAGTFihBYvXqz33ntPv/zyi6ZPn669e/fe8LRctWrV9MMPP+j48eM6d+6ccnJy8u3XsWNHbd261S4I9enTR1arVQMGDNC+ffu0evVqvfrqq4qKirLbZnx8vO6//35Vr179hscSMAUDwF2nf//+Rrdu3fKd16pVK2PUqFF52mfNmmUEBAQYHh4eRseOHY3ly5cbkowLFy7Y+sTGxhpBQUGGp6enERkZabzyyitGcHCwbX5mZqYxatQow8vLy/Dx8TGioqKMyMjIAmvJtXDhQqNZs2Z2bUuXLjUk5ZkmT55s67NlyxbDx8fHuHLlyk2OiGHMnz/fkGRERkbata9evdpo2rSp4eXlZXh6ehrNmjUzNm7cWOB6Cqor9zikpaUZI0aMMAIDA43SpUsbQUFBRt++fY3ExETbOqZNm2b4+fkZZcuWNQYNGmSMHDnSbv///P4dOnTIaNasmeHh4WFIMo4dO5ZvbVlZWUblypWN9evX27Xv3bvXaNGihWG1Wo1KlSoZU6ZMMXJycuz6REREGDExMTc6hIBpWAyjmE4GA0ABrl27ptq1a+ujjz6yuyD5Zp566ik1bNhQEyZMuI3V3X4dOnRQpUqV9P7779/yuhYsWKD//Oc/2rBhQ6GX2bdvn9q1a6eff/75pne3AWbg6uwCAJifu7u7li9frnPnzhV6mYyMDDVo0EBjxoy5jZUVvytXrmjhwoXq2LGjXFxctGLFCm3cuFFxcXHFsv5nnnlGFy5cUHp6ut0Tn2/kzJkzWr58OcEG9wxGbgCgGF29elWPPfaYdu7cqYyMDNWuXVsvvvii/vKXvzi7NOCeQbgBAACmwt1SAADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVAg3AADAVP4fcWfEIA9CrvgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fraud_dist = fraud[\"fraud\"].value_counts(normalize=True)\n",
    "print(fraud_dist)\n",
    "\n",
    "fraud_dist.plot(kind=\"bar\", title=\"Fraud vs Legit Transactions\")\n",
    "plt.xlabel(\"Fraud (1) vs Legit (0)\")\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.877857</td>\n",
       "      <td>0.311140</td>\n",
       "      <td>1.945940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.829943</td>\n",
       "      <td>0.175592</td>\n",
       "      <td>1.294219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.091079</td>\n",
       "      <td>0.805153</td>\n",
       "      <td>0.427715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.247564</td>\n",
       "      <td>5.600044</td>\n",
       "      <td>0.362663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.190936</td>\n",
       "      <td>0.566486</td>\n",
       "      <td>2.222767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance_from_home  distance_from_last_transaction  \\\n",
       "0           57.877857                        0.311140   \n",
       "1           10.829943                        0.175592   \n",
       "2            5.091079                        0.805153   \n",
       "3            2.247564                        5.600044   \n",
       "4           44.190936                        0.566486   \n",
       "\n",
       "   ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "0                        1.945940              1.0        1.0   \n",
       "1                        1.294219              1.0        0.0   \n",
       "2                        0.427715              1.0        0.0   \n",
       "3                        0.362663              1.0        1.0   \n",
       "4                        2.222767              1.0        1.0   \n",
       "\n",
       "   used_pin_number  online_order  fraud  \n",
       "0              0.0           0.0    0.0  \n",
       "1              0.0           0.0    0.0  \n",
       "2              0.0           1.0    0.0  \n",
       "3              0.0           1.0    0.0  \n",
       "4              0.0           1.0    0.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = fraud.drop(columns=[\"fraud\"])\n",
    "target = fraud[\"fraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.20,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=0)\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.959215"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.99      0.98    182615\n",
      "         1.0       0.89      0.60      0.72     17385\n",
      "\n",
      "    accuracy                           0.96    200000\n",
      "   macro avg       0.93      0.80      0.85    200000\n",
      "weighted avg       0.96      0.96      0.96    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred = pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OVERSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.357077</td>\n",
       "      <td>-0.150122</td>\n",
       "      <td>-0.423839</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>1.361603</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.194157</td>\n",
       "      <td>-0.185739</td>\n",
       "      <td>-0.433963</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>1.361603</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.443734</td>\n",
       "      <td>-0.150915</td>\n",
       "      <td>-0.484329</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.402217</td>\n",
       "      <td>-0.166800</td>\n",
       "      <td>-0.460903</td>\n",
       "      <td>-2.729870</td>\n",
       "      <td>1.361603</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>-1.36517</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.070140</td>\n",
       "      <td>-0.185709</td>\n",
       "      <td>-0.414141</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>1.361603</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>-1.36517</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799995</th>\n",
       "      <td>0.686916</td>\n",
       "      <td>-0.071705</td>\n",
       "      <td>-0.606513</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799996</th>\n",
       "      <td>-0.359697</td>\n",
       "      <td>0.294316</td>\n",
       "      <td>0.106885</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799997</th>\n",
       "      <td>0.002457</td>\n",
       "      <td>-0.023525</td>\n",
       "      <td>-0.477266</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>2.989238</td>\n",
       "      <td>-1.36517</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799998</th>\n",
       "      <td>-0.223923</td>\n",
       "      <td>-0.185220</td>\n",
       "      <td>-0.010973</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799999</th>\n",
       "      <td>0.350306</td>\n",
       "      <td>-0.167276</td>\n",
       "      <td>0.498380</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>1.361603</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>-1.36517</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance_from_home  distance_from_last_transaction  \\\n",
       "0                -0.357077                       -0.150122   \n",
       "1                 0.194157                       -0.185739   \n",
       "2                 0.443734                       -0.150915   \n",
       "3                -0.402217                       -0.166800   \n",
       "4                -0.070140                       -0.185709   \n",
       "...                    ...                             ...   \n",
       "799995            0.686916                       -0.071705   \n",
       "799996           -0.359697                        0.294316   \n",
       "799997            0.002457                       -0.023525   \n",
       "799998           -0.223923                       -0.185220   \n",
       "799999            0.350306                       -0.167276   \n",
       "\n",
       "        ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "0                            -0.423839         0.366318   1.361603   \n",
       "1                            -0.433963         0.366318   1.361603   \n",
       "2                            -0.484329         0.366318  -0.734428   \n",
       "3                            -0.460903        -2.729870   1.361603   \n",
       "4                            -0.414141         0.366318   1.361603   \n",
       "...                                ...              ...        ...   \n",
       "799995                       -0.606513         0.366318  -0.734428   \n",
       "799996                        0.106885         0.366318  -0.734428   \n",
       "799997                       -0.477266         0.366318  -0.734428   \n",
       "799998                       -0.010973         0.366318  -0.734428   \n",
       "799999                        0.498380         0.366318   1.361603   \n",
       "\n",
       "        used_pin_number  online_order  fraud  \n",
       "0             -0.334533       0.73251    0.0  \n",
       "1             -0.334533       0.73251    0.0  \n",
       "2             -0.334533       0.73251    0.0  \n",
       "3             -0.334533      -1.36517    0.0  \n",
       "4             -0.334533      -1.36517    0.0  \n",
       "...                 ...           ...    ...  \n",
       "799995        -0.334533       0.73251    0.0  \n",
       "799996        -0.334533       0.73251    0.0  \n",
       "799997         2.989238      -1.36517    0.0  \n",
       "799998        -0.334533       0.73251    0.0  \n",
       "799999        -0.334533      -1.36517    0.0  \n",
       "\n",
       "[800000 rows x 8 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.DataFrame(X_train_scaled, columns = X_train.columns)\n",
    "train[\"fraud\"] = y_train.values\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fraud\n",
       "0.0    729982\n",
       "1.0     70018\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"fraud\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_df = train[train[\"fraud\"]==1]\n",
    "no_fraud_df = train[train[\"fraud\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_df_oversampled = resample(fraud_df, n_samples=len(no_fraud_df), replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97310</th>\n",
       "      <td>0.202416</td>\n",
       "      <td>-0.131635</td>\n",
       "      <td>1.237795</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>1.361603</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408098</th>\n",
       "      <td>0.115434</td>\n",
       "      <td>-0.175532</td>\n",
       "      <td>2.347710</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113315</th>\n",
       "      <td>5.930308</td>\n",
       "      <td>-0.177403</td>\n",
       "      <td>-0.111147</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656601</th>\n",
       "      <td>5.549813</td>\n",
       "      <td>-0.180911</td>\n",
       "      <td>0.258150</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556741</th>\n",
       "      <td>2.377128</td>\n",
       "      <td>0.403251</td>\n",
       "      <td>-0.448098</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187826</th>\n",
       "      <td>1.376229</td>\n",
       "      <td>9.460788</td>\n",
       "      <td>2.850273</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500517</th>\n",
       "      <td>1.360149</td>\n",
       "      <td>-0.148589</td>\n",
       "      <td>-0.065932</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62114</th>\n",
       "      <td>-0.368756</td>\n",
       "      <td>-0.183650</td>\n",
       "      <td>2.350943</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42679</th>\n",
       "      <td>0.646152</td>\n",
       "      <td>1.448933</td>\n",
       "      <td>0.789661</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352496</th>\n",
       "      <td>-0.368736</td>\n",
       "      <td>-0.150506</td>\n",
       "      <td>1.421941</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>729982 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance_from_home  distance_from_last_transaction  \\\n",
       "97310             0.202416                       -0.131635   \n",
       "408098            0.115434                       -0.175532   \n",
       "113315            5.930308                       -0.177403   \n",
       "656601            5.549813                       -0.180911   \n",
       "556741            2.377128                        0.403251   \n",
       "...                    ...                             ...   \n",
       "187826            1.376229                        9.460788   \n",
       "500517            1.360149                       -0.148589   \n",
       "62114            -0.368756                       -0.183650   \n",
       "42679             0.646152                        1.448933   \n",
       "352496           -0.368736                       -0.150506   \n",
       "\n",
       "        ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "97310                         1.237795         0.366318   1.361603   \n",
       "408098                        2.347710         0.366318  -0.734428   \n",
       "113315                       -0.111147         0.366318  -0.734428   \n",
       "656601                        0.258150         0.366318  -0.734428   \n",
       "556741                       -0.448098         0.366318  -0.734428   \n",
       "...                                ...              ...        ...   \n",
       "187826                        2.850273         0.366318  -0.734428   \n",
       "500517                       -0.065932         0.366318  -0.734428   \n",
       "62114                         2.350943         0.366318  -0.734428   \n",
       "42679                         0.789661         0.366318  -0.734428   \n",
       "352496                        1.421941         0.366318  -0.734428   \n",
       "\n",
       "        used_pin_number  online_order  fraud  \n",
       "97310         -0.334533       0.73251    1.0  \n",
       "408098        -0.334533       0.73251    1.0  \n",
       "113315        -0.334533       0.73251    1.0  \n",
       "656601        -0.334533       0.73251    1.0  \n",
       "556741        -0.334533       0.73251    1.0  \n",
       "...                 ...           ...    ...  \n",
       "187826        -0.334533       0.73251    1.0  \n",
       "500517        -0.334533       0.73251    1.0  \n",
       "62114         -0.334533       0.73251    1.0  \n",
       "42679         -0.334533       0.73251    1.0  \n",
       "352496        -0.334533       0.73251    1.0  \n",
       "\n",
       "[729982 rows x 8 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_df_oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.357077</td>\n",
       "      <td>-0.150122</td>\n",
       "      <td>-0.423839</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>1.361603</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.194157</td>\n",
       "      <td>-0.185739</td>\n",
       "      <td>-0.433963</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>1.361603</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.443734</td>\n",
       "      <td>-0.150915</td>\n",
       "      <td>-0.484329</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.402217</td>\n",
       "      <td>-0.166800</td>\n",
       "      <td>-0.460903</td>\n",
       "      <td>-2.729870</td>\n",
       "      <td>1.361603</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>-1.36517</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.070140</td>\n",
       "      <td>-0.185709</td>\n",
       "      <td>-0.414141</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>1.361603</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>-1.36517</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799995</th>\n",
       "      <td>0.686916</td>\n",
       "      <td>-0.071705</td>\n",
       "      <td>-0.606513</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799996</th>\n",
       "      <td>-0.359697</td>\n",
       "      <td>0.294316</td>\n",
       "      <td>0.106885</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799997</th>\n",
       "      <td>0.002457</td>\n",
       "      <td>-0.023525</td>\n",
       "      <td>-0.477266</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>2.989238</td>\n",
       "      <td>-1.36517</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799998</th>\n",
       "      <td>-0.223923</td>\n",
       "      <td>-0.185220</td>\n",
       "      <td>-0.010973</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799999</th>\n",
       "      <td>0.350306</td>\n",
       "      <td>-0.167276</td>\n",
       "      <td>0.498380</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>1.361603</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>-1.36517</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>729982 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance_from_home  distance_from_last_transaction  \\\n",
       "0                -0.357077                       -0.150122   \n",
       "1                 0.194157                       -0.185739   \n",
       "2                 0.443734                       -0.150915   \n",
       "3                -0.402217                       -0.166800   \n",
       "4                -0.070140                       -0.185709   \n",
       "...                    ...                             ...   \n",
       "799995            0.686916                       -0.071705   \n",
       "799996           -0.359697                        0.294316   \n",
       "799997            0.002457                       -0.023525   \n",
       "799998           -0.223923                       -0.185220   \n",
       "799999            0.350306                       -0.167276   \n",
       "\n",
       "        ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "0                            -0.423839         0.366318   1.361603   \n",
       "1                            -0.433963         0.366318   1.361603   \n",
       "2                            -0.484329         0.366318  -0.734428   \n",
       "3                            -0.460903        -2.729870   1.361603   \n",
       "4                            -0.414141         0.366318   1.361603   \n",
       "...                                ...              ...        ...   \n",
       "799995                       -0.606513         0.366318  -0.734428   \n",
       "799996                        0.106885         0.366318  -0.734428   \n",
       "799997                       -0.477266         0.366318  -0.734428   \n",
       "799998                       -0.010973         0.366318  -0.734428   \n",
       "799999                        0.498380         0.366318   1.361603   \n",
       "\n",
       "        used_pin_number  online_order  fraud  \n",
       "0             -0.334533       0.73251    0.0  \n",
       "1             -0.334533       0.73251    0.0  \n",
       "2             -0.334533       0.73251    0.0  \n",
       "3             -0.334533      -1.36517    0.0  \n",
       "4             -0.334533      -1.36517    0.0  \n",
       "...                 ...           ...    ...  \n",
       "799995        -0.334533       0.73251    0.0  \n",
       "799996        -0.334533       0.73251    0.0  \n",
       "799997         2.989238      -1.36517    0.0  \n",
       "799998        -0.334533       0.73251    0.0  \n",
       "799999        -0.334533      -1.36517    0.0  \n",
       "\n",
       "[729982 rows x 8 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_fraud_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97310</th>\n",
       "      <td>0.202416</td>\n",
       "      <td>-0.131635</td>\n",
       "      <td>1.237795</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>1.361603</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408098</th>\n",
       "      <td>0.115434</td>\n",
       "      <td>-0.175532</td>\n",
       "      <td>2.347710</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113315</th>\n",
       "      <td>5.930308</td>\n",
       "      <td>-0.177403</td>\n",
       "      <td>-0.111147</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656601</th>\n",
       "      <td>5.549813</td>\n",
       "      <td>-0.180911</td>\n",
       "      <td>0.258150</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556741</th>\n",
       "      <td>2.377128</td>\n",
       "      <td>0.403251</td>\n",
       "      <td>-0.448098</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799995</th>\n",
       "      <td>0.686916</td>\n",
       "      <td>-0.071705</td>\n",
       "      <td>-0.606513</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799996</th>\n",
       "      <td>-0.359697</td>\n",
       "      <td>0.294316</td>\n",
       "      <td>0.106885</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799997</th>\n",
       "      <td>0.002457</td>\n",
       "      <td>-0.023525</td>\n",
       "      <td>-0.477266</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>2.989238</td>\n",
       "      <td>-1.36517</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799998</th>\n",
       "      <td>-0.223923</td>\n",
       "      <td>-0.185220</td>\n",
       "      <td>-0.010973</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799999</th>\n",
       "      <td>0.350306</td>\n",
       "      <td>-0.167276</td>\n",
       "      <td>0.498380</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>1.361603</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>-1.36517</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459964 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance_from_home  distance_from_last_transaction  \\\n",
       "97310             0.202416                       -0.131635   \n",
       "408098            0.115434                       -0.175532   \n",
       "113315            5.930308                       -0.177403   \n",
       "656601            5.549813                       -0.180911   \n",
       "556741            2.377128                        0.403251   \n",
       "...                    ...                             ...   \n",
       "799995            0.686916                       -0.071705   \n",
       "799996           -0.359697                        0.294316   \n",
       "799997            0.002457                       -0.023525   \n",
       "799998           -0.223923                       -0.185220   \n",
       "799999            0.350306                       -0.167276   \n",
       "\n",
       "        ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "97310                         1.237795         0.366318   1.361603   \n",
       "408098                        2.347710         0.366318  -0.734428   \n",
       "113315                       -0.111147         0.366318  -0.734428   \n",
       "656601                        0.258150         0.366318  -0.734428   \n",
       "556741                       -0.448098         0.366318  -0.734428   \n",
       "...                                ...              ...        ...   \n",
       "799995                       -0.606513         0.366318  -0.734428   \n",
       "799996                        0.106885         0.366318  -0.734428   \n",
       "799997                       -0.477266         0.366318  -0.734428   \n",
       "799998                       -0.010973         0.366318  -0.734428   \n",
       "799999                        0.498380         0.366318   1.361603   \n",
       "\n",
       "        used_pin_number  online_order  fraud  \n",
       "97310         -0.334533       0.73251    1.0  \n",
       "408098        -0.334533       0.73251    1.0  \n",
       "113315        -0.334533       0.73251    1.0  \n",
       "656601        -0.334533       0.73251    1.0  \n",
       "556741        -0.334533       0.73251    1.0  \n",
       "...                 ...           ...    ...  \n",
       "799995        -0.334533       0.73251    0.0  \n",
       "799996        -0.334533       0.73251    0.0  \n",
       "799997         2.989238      -1.36517    0.0  \n",
       "799998        -0.334533       0.73251    0.0  \n",
       "799999        -0.334533      -1.36517    0.0  \n",
       "\n",
       "[1459964 rows x 8 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_oversampled = pd.concat([fraud_df_oversampled, no_fraud_df])\n",
    "train_oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fraud\n",
       "1.0    729982\n",
       "0.0    729982\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_oversampled[\"fraud\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = train_oversampled.drop(columns=\"fraud\")\n",
    "y_train_over = train_oversampled[\"fraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ricardo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.934125"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ricardo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.93      0.96    182615\n",
      "         1.0       0.57      0.95      0.71     17385\n",
      "\n",
      "    accuracy                           0.93    200000\n",
      "   macro avg       0.78      0.94      0.84    200000\n",
      "weighted avg       0.96      0.93      0.94    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = log_reg.predict(X_test_scaled)\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred = pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNDERSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.357077</td>\n",
       "      <td>-0.150122</td>\n",
       "      <td>-0.423839</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>1.361603</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.194157</td>\n",
       "      <td>-0.185739</td>\n",
       "      <td>-0.433963</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>1.361603</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.443734</td>\n",
       "      <td>-0.150915</td>\n",
       "      <td>-0.484329</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.402217</td>\n",
       "      <td>-0.166800</td>\n",
       "      <td>-0.460903</td>\n",
       "      <td>-2.729870</td>\n",
       "      <td>1.361603</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>-1.36517</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.070140</td>\n",
       "      <td>-0.185709</td>\n",
       "      <td>-0.414141</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>1.361603</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>-1.36517</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799995</th>\n",
       "      <td>0.686916</td>\n",
       "      <td>-0.071705</td>\n",
       "      <td>-0.606513</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799996</th>\n",
       "      <td>-0.359697</td>\n",
       "      <td>0.294316</td>\n",
       "      <td>0.106885</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799997</th>\n",
       "      <td>0.002457</td>\n",
       "      <td>-0.023525</td>\n",
       "      <td>-0.477266</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>2.989238</td>\n",
       "      <td>-1.36517</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799998</th>\n",
       "      <td>-0.223923</td>\n",
       "      <td>-0.185220</td>\n",
       "      <td>-0.010973</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799999</th>\n",
       "      <td>0.350306</td>\n",
       "      <td>-0.167276</td>\n",
       "      <td>0.498380</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>1.361603</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>-1.36517</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance_from_home  distance_from_last_transaction  \\\n",
       "0                -0.357077                       -0.150122   \n",
       "1                 0.194157                       -0.185739   \n",
       "2                 0.443734                       -0.150915   \n",
       "3                -0.402217                       -0.166800   \n",
       "4                -0.070140                       -0.185709   \n",
       "...                    ...                             ...   \n",
       "799995            0.686916                       -0.071705   \n",
       "799996           -0.359697                        0.294316   \n",
       "799997            0.002457                       -0.023525   \n",
       "799998           -0.223923                       -0.185220   \n",
       "799999            0.350306                       -0.167276   \n",
       "\n",
       "        ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "0                            -0.423839         0.366318   1.361603   \n",
       "1                            -0.433963         0.366318   1.361603   \n",
       "2                            -0.484329         0.366318  -0.734428   \n",
       "3                            -0.460903        -2.729870   1.361603   \n",
       "4                            -0.414141         0.366318   1.361603   \n",
       "...                                ...              ...        ...   \n",
       "799995                       -0.606513         0.366318  -0.734428   \n",
       "799996                        0.106885         0.366318  -0.734428   \n",
       "799997                       -0.477266         0.366318  -0.734428   \n",
       "799998                       -0.010973         0.366318  -0.734428   \n",
       "799999                        0.498380         0.366318   1.361603   \n",
       "\n",
       "        used_pin_number  online_order  fraud  \n",
       "0             -0.334533       0.73251    0.0  \n",
       "1             -0.334533       0.73251    0.0  \n",
       "2             -0.334533       0.73251    0.0  \n",
       "3             -0.334533      -1.36517    0.0  \n",
       "4             -0.334533      -1.36517    0.0  \n",
       "...                 ...           ...    ...  \n",
       "799995        -0.334533       0.73251    0.0  \n",
       "799996        -0.334533       0.73251    0.0  \n",
       "799997         2.989238      -1.36517    0.0  \n",
       "799998        -0.334533       0.73251    0.0  \n",
       "799999        -0.334533      -1.36517    0.0  \n",
       "\n",
       "[800000 rows x 8 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>280277</th>\n",
       "      <td>-0.374987</td>\n",
       "      <td>-0.172740</td>\n",
       "      <td>-0.285736</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657950</th>\n",
       "      <td>-0.300201</td>\n",
       "      <td>1.218911</td>\n",
       "      <td>-0.142259</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>1.361603</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558074</th>\n",
       "      <td>-0.036789</td>\n",
       "      <td>0.096124</td>\n",
       "      <td>-0.452162</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>-1.36517</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752799</th>\n",
       "      <td>-0.252904</td>\n",
       "      <td>-0.087447</td>\n",
       "      <td>0.084824</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698167</th>\n",
       "      <td>-0.404792</td>\n",
       "      <td>-0.011732</td>\n",
       "      <td>-0.243266</td>\n",
       "      <td>-2.729870</td>\n",
       "      <td>1.361603</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145346</th>\n",
       "      <td>0.769529</td>\n",
       "      <td>-0.040638</td>\n",
       "      <td>0.374281</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>-1.36517</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748697</th>\n",
       "      <td>-0.189432</td>\n",
       "      <td>0.053647</td>\n",
       "      <td>0.111266</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307316</th>\n",
       "      <td>-0.348801</td>\n",
       "      <td>-0.147106</td>\n",
       "      <td>1.582413</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>2.989238</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388442</th>\n",
       "      <td>0.467115</td>\n",
       "      <td>-0.123770</td>\n",
       "      <td>-0.528182</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>-1.36517</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231845</th>\n",
       "      <td>-0.118421</td>\n",
       "      <td>-0.160627</td>\n",
       "      <td>-0.485810</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>1.361603</td>\n",
       "      <td>2.989238</td>\n",
       "      <td>-1.36517</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70018 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance_from_home  distance_from_last_transaction  \\\n",
       "280277           -0.374987                       -0.172740   \n",
       "657950           -0.300201                        1.218911   \n",
       "558074           -0.036789                        0.096124   \n",
       "752799           -0.252904                       -0.087447   \n",
       "698167           -0.404792                       -0.011732   \n",
       "...                    ...                             ...   \n",
       "145346            0.769529                       -0.040638   \n",
       "748697           -0.189432                        0.053647   \n",
       "307316           -0.348801                       -0.147106   \n",
       "388442            0.467115                       -0.123770   \n",
       "231845           -0.118421                       -0.160627   \n",
       "\n",
       "        ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "280277                       -0.285736         0.366318  -0.734428   \n",
       "657950                       -0.142259         0.366318   1.361603   \n",
       "558074                       -0.452162         0.366318  -0.734428   \n",
       "752799                        0.084824         0.366318  -0.734428   \n",
       "698167                       -0.243266        -2.729870   1.361603   \n",
       "...                                ...              ...        ...   \n",
       "145346                        0.374281         0.366318  -0.734428   \n",
       "748697                        0.111266         0.366318  -0.734428   \n",
       "307316                        1.582413         0.366318  -0.734428   \n",
       "388442                       -0.528182         0.366318  -0.734428   \n",
       "231845                       -0.485810         0.366318   1.361603   \n",
       "\n",
       "        used_pin_number  online_order  fraud  \n",
       "280277        -0.334533       0.73251    0.0  \n",
       "657950        -0.334533       0.73251    0.0  \n",
       "558074        -0.334533      -1.36517    0.0  \n",
       "752799        -0.334533       0.73251    0.0  \n",
       "698167        -0.334533       0.73251    0.0  \n",
       "...                 ...           ...    ...  \n",
       "145346        -0.334533      -1.36517    0.0  \n",
       "748697        -0.334533       0.73251    0.0  \n",
       "307316         2.989238       0.73251    0.0  \n",
       "388442        -0.334533      -1.36517    0.0  \n",
       "231845         2.989238      -1.36517    0.0  \n",
       "\n",
       "[70018 rows x 8 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_fraud_undersampled = resample(no_fraud_df, n_samples=len(fraud_df))\n",
    "no_fraud_undersampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5.750327</td>\n",
       "      <td>-0.177389</td>\n",
       "      <td>0.341349</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-0.392963</td>\n",
       "      <td>-0.157910</td>\n",
       "      <td>1.319248</td>\n",
       "      <td>-2.729870</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>-1.36517</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>-0.150089</td>\n",
       "      <td>-0.130154</td>\n",
       "      <td>0.922150</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>-0.408534</td>\n",
       "      <td>2.993662</td>\n",
       "      <td>0.776164</td>\n",
       "      <td>-2.729870</td>\n",
       "      <td>1.361603</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1.415853</td>\n",
       "      <td>-0.148294</td>\n",
       "      <td>-0.573715</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145346</th>\n",
       "      <td>0.769529</td>\n",
       "      <td>-0.040638</td>\n",
       "      <td>0.374281</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>-1.36517</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748697</th>\n",
       "      <td>-0.189432</td>\n",
       "      <td>0.053647</td>\n",
       "      <td>0.111266</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307316</th>\n",
       "      <td>-0.348801</td>\n",
       "      <td>-0.147106</td>\n",
       "      <td>1.582413</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>2.989238</td>\n",
       "      <td>0.73251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388442</th>\n",
       "      <td>0.467115</td>\n",
       "      <td>-0.123770</td>\n",
       "      <td>-0.528182</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>-0.734428</td>\n",
       "      <td>-0.334533</td>\n",
       "      <td>-1.36517</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231845</th>\n",
       "      <td>-0.118421</td>\n",
       "      <td>-0.160627</td>\n",
       "      <td>-0.485810</td>\n",
       "      <td>0.366318</td>\n",
       "      <td>1.361603</td>\n",
       "      <td>2.989238</td>\n",
       "      <td>-1.36517</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140036 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance_from_home  distance_from_last_transaction  \\\n",
       "32                5.750327                       -0.177389   \n",
       "49               -0.392963                       -0.157910   \n",
       "74               -0.150089                       -0.130154   \n",
       "111              -0.408534                        2.993662   \n",
       "114               1.415853                       -0.148294   \n",
       "...                    ...                             ...   \n",
       "145346            0.769529                       -0.040638   \n",
       "748697           -0.189432                        0.053647   \n",
       "307316           -0.348801                       -0.147106   \n",
       "388442            0.467115                       -0.123770   \n",
       "231845           -0.118421                       -0.160627   \n",
       "\n",
       "        ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "32                            0.341349         0.366318  -0.734428   \n",
       "49                            1.319248        -2.729870  -0.734428   \n",
       "74                            0.922150         0.366318  -0.734428   \n",
       "111                           0.776164        -2.729870   1.361603   \n",
       "114                          -0.573715         0.366318  -0.734428   \n",
       "...                                ...              ...        ...   \n",
       "145346                        0.374281         0.366318  -0.734428   \n",
       "748697                        0.111266         0.366318  -0.734428   \n",
       "307316                        1.582413         0.366318  -0.734428   \n",
       "388442                       -0.528182         0.366318  -0.734428   \n",
       "231845                       -0.485810         0.366318   1.361603   \n",
       "\n",
       "        used_pin_number  online_order  fraud  \n",
       "32            -0.334533       0.73251    1.0  \n",
       "49            -0.334533      -1.36517    1.0  \n",
       "74            -0.334533       0.73251    1.0  \n",
       "111           -0.334533       0.73251    1.0  \n",
       "114           -0.334533       0.73251    1.0  \n",
       "...                 ...           ...    ...  \n",
       "145346        -0.334533      -1.36517    0.0  \n",
       "748697        -0.334533       0.73251    0.0  \n",
       "307316         2.989238       0.73251    0.0  \n",
       "388442        -0.334533      -1.36517    0.0  \n",
       "231845         2.989238      -1.36517    0.0  \n",
       "\n",
       "[140036 rows x 8 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_under = pd.concat([fraud_df, no_fraud_undersampled])\n",
    "train_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_under = train_under.drop(columns=\"fraud\")\n",
    "y_train_under = train_under[\"fraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ricardo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.93      0.96    182615\n",
      "         1.0       0.57      0.95      0.71     17385\n",
      "\n",
      "    accuracy                           0.93    200000\n",
      "   macro avg       0.78      0.94      0.84    200000\n",
      "weighted avg       0.96      0.93      0.94    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_under, y_train_under)\n",
    "\n",
    "\n",
    "pred = log_reg.predict(X_test_scaled)\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred = pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm, y_train_sm = smote.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.93      0.96    182615\n",
      "         1.0       0.57      0.95      0.71     17385\n",
      "\n",
      "    accuracy                           0.93    200000\n",
      "   macro avg       0.78      0.94      0.84    200000\n",
      "weighted avg       0.96      0.93      0.94    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "\n",
    "pred = log_reg.predict(X_test_scaled)\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred = pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
